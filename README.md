# **ChatHuman: Language-driven 3D Human Understanding with Retrieval-Augmented Tool Reasoning**

<p align="center">
  <a href='https://arxiv.org/abs/2405.04533'>
    <img src='https://img.shields.io/badge/Arxiv-2307.00818-A42C25?style=flat&logo=arXiv&logoColor=A42C25'>
  </a>
  <a href='https://arxiv.org/abs/2405.04533pdf'>
    <img src='https://img.shields.io/badge/Paper-PDF-yellow?style=flat&logo=arXiv&logoColor=yellow'>
  </a>
  <a href='https://chathuman.github.io'>
  <img src='https://img.shields.io/badge/Project-Page-pink?style=flat&logo=Google%20chrome&logoColor=pink'>
  </a>
  <a href='https://youtu.be/0a0ZYJgzdWE'>
  <img src='https://img.shields.io/badge/YouTube-Video-EA3323?style=flat&logo=youtube&logoColor=EA3323'>
  </a>
  <a href='https://github.com/linjing7/ChatHuman'>
    <img src='https://img.shields.io/badge/GitHub-Code-black?style=flat&logo=github&logoColor=white'>
  </a>
  <a href="" target='_blank'>
    <img src="https://visitor-badge.laobi.icu/badge?page_id=linjing7.ChatHuman&left_color=gray&right_color=orange">
  </a>
</p>

This repository contains the implementation of the following paper:

> ChatHuman: Language-driven 3D Human Understanding with Retrieval-Augmented Tool Reasoning
> [Jing Lin](https://jinglin7.github.io/)^3,4,*^, [Yao Feng](https://scholar.google.com/citations?user=wNQQhSIAAAAJ&hl=en)^1,2,3,*^,[Weiyang Liu](https://wyliu.com/)^1,2,3^,[Michael J. Black](https://ps.is.mpg.de/person/black)^3^
>
> ^1^Max Planck Institute for Intelligent Systems, ^2^ETH Z√ºrich, ^3^Meshcapade, ^4^Tsinghua University, ^5^University of Cambridge

![teaser](images/teaser.jpeg)

## ü§ù Citation  

If you find this repository useful for your work, please consider citing it as follows:

```  
@inproceedings{jing2024chathuman,
    author={Lin, Jing and Feng, Yao and Liu, Weiyang and  Black, Michael J}
    title={{ChatHuman}: Language-driven {3D} Human Understanding with Retrieval-Augmented Tool Reasoning},
 journal={arXiv preprint arXiv:2405.04533},
 year = {2024}}
```